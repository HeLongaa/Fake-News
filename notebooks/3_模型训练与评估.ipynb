{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480bab8d",
   "metadata": {},
   "source": [
    "# 虚假新闻检测 - 模型训练与评估\n",
    "\n",
    "本notebook实现模型的训练、评估和分析流程，包括：\n",
    "\n",
    "1. 数据准备\n",
    "   - 加载预处理后的特征\n",
    "   - 数据集划分\n",
    "   - 特征标准化\n",
    "\n",
    "2. 模型训练\n",
    "   - BERT模型\n",
    "   - BiLSTM+Attention模型\n",
    "   - 传统机器学习模型（SVM、随机森林）\n",
    "\n",
    "3. 模型评估\n",
    "   - 准确率、精确率、召回率、F1分数\n",
    "   - 混淆矩阵分析\n",
    "   - ROC和PR曲线\n",
    "\n",
    "4. 错误分析\n",
    "   - 错误预测案例分析\n",
    "   - 模型解释性分析\n",
    "   - 改进建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "from transformers import BertTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# 设置显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # 对于macOS\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7db1d2",
   "metadata": {},
   "source": [
    "## 1. 数据准备\n",
    "\n",
    "首先加载并准备训练数据：\n",
    "1. 加载特征工程生成的特征\n",
    "2. 加载对应的标签\n",
    "3. 划分训练集、验证集和测试集\n",
    "4. 数据标准化和格式转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载特征和标签\n",
    "features_path = Path('../results/combined_features.npy')\n",
    "labels_path = Path('../results/labels.npy')\n",
    "\n",
    "X = np.load(features_path)\n",
    "y = np.load(labels_path)\n",
    "\n",
    "print(f\"特征形状: {X.shape}\")\n",
    "print(f\"标签形状: {y.shape}\")\n",
    "print(f\"\\n标签分布:\\n{pd.Series(y).value_counts(normalize=True)}\")\n",
    "\n",
    "# 划分数据集\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=SEED, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"\\n数据集划分:\")\n",
    "print(f\"训练集: {X_train.shape[0]} 样本\")\n",
    "print(f\"验证集: {X_val.shape[0]} 样本\")\n",
    "print(f\"测试集: {X_test.shape[0]} 样本\")\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 创建数据加载器\n",
    "class RumorDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = RumorDataset(X_train_scaled, y_train)\n",
    "val_dataset = RumorDataset(X_val_scaled, y_val)\n",
    "test_dataset = RumorDataset(X_test_scaled, y_test)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 可视化标签分布\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(131)\n",
    "plt.pie(pd.Series(y_train).value_counts(normalize=True), \n",
    "        labels=['非谣言', '谣言'], autopct='%1.1f%%')\n",
    "plt.title('训练集标签分布')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.pie(pd.Series(y_val).value_counts(normalize=True), \n",
    "        labels=['非谣言', '谣言'], autopct='%1.1f%%')\n",
    "plt.title('验证集标签分布')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.pie(pd.Series(y_test).value_counts(normalize=True), \n",
    "        labels=['非谣言', '谣言'], autopct='%1.1f%%')\n",
    "plt.title('测试集标签分布')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced559a5",
   "metadata": {},
   "source": [
    "## 2. 模型定义和训练\n",
    "\n",
    "我们将实现并训练以下模型：\n",
    "1. 基于神经网络的模型：\n",
    "   - 多层感知机 (MLP)\n",
    "   - BERT分类器\n",
    "   - BiLSTM+Attention\n",
    "\n",
    "2. 传统机器学习模型：\n",
    "   - SVM\n",
    "   - 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估函数\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            outputs = model(features)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual_labels.extend(labels.numpy())\n",
    "    \n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        actual_labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                scheduler, device, epochs=10):\n",
    "    history = []\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # 计算平均训练损失\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_metrics['f1'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1']\n",
    "            torch.save(model.state_dict(), '../results/models/best_model.pt')\n",
    "        \n",
    "        # 记录训练信息\n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            **val_metrics\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs}:')\n",
    "        print(f'训练损失: {train_loss:.4f}')\n",
    "        print(f'验证集指标: {val_metrics}')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 定义MLP模型\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# 训练MLP模型\n",
    "print(\"训练MLP模型...\")\n",
    "mlp_model = MLPClassifier(X_train.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "mlp_history = train_model(\n",
    "    mlp_model, train_loader, val_loader,\n",
    "    criterion, optimizer, scheduler, device\n",
    ")\n",
    "\n",
    "# 可视化训练过程\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot([h['train_loss'] for h in mlp_history], label='训练损失')\n",
    "plt.title('训练损失曲线')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot([h['f1'] for h in mlp_history], label='F1分数')\n",
    "plt.plot([h['accuracy'] for h in mlp_history], label='准确率')\n",
    "plt.title('验证集评估指标')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 在测试集上评估MLP模型\n",
    "mlp_test_metrics = evaluate_model(mlp_model, test_loader, device)\n",
    "print(\"\\nMLP模型测试集表现:\")\n",
    "print(mlp_test_metrics)\n",
    "\n",
    "# 训练传统机器学习模型\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM模型\n",
    "print(\"\\n训练SVM模型...\")\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_pred = svm.predict(X_test_scaled)\n",
    "svm_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, svm_pred),\n",
    "    **dict(zip(\n",
    "        ['precision', 'recall', 'f1', '_'],\n",
    "        precision_recall_fscore_support(y_test, svm_pred, average='binary')\n",
    "    ))\n",
    "}\n",
    "\n",
    "print(\"SVM模型测试集表现:\")\n",
    "print(svm_metrics)\n",
    "\n",
    "# 随机森林模型\n",
    "print(\"\\n训练随机森林模型...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=SEED)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "rf_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, rf_pred),\n",
    "    **dict(zip(\n",
    "        ['precision', 'recall', 'f1', '_'],\n",
    "        precision_recall_fscore_support(y_test, rf_pred, average='binary')\n",
    "    ))\n",
    "}\n",
    "\n",
    "print(\"随机森林模型测试集表现:\")\n",
    "print(rf_metrics)\n",
    "\n",
    "# 比较所有模型性能\n",
    "models_comparison = pd.DataFrame({\n",
    "    'MLP': mlp_test_metrics,\n",
    "    'SVM': svm_metrics,\n",
    "    'Random Forest': rf_metrics\n",
    "}).T\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "models_comparison[['accuracy', 'precision', 'recall', 'f1']].plot(kind='bar')\n",
    "plt.title('模型性能比较')\n",
    "plt.xlabel('模型')\n",
    "plt.ylabel('分数')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a491f69",
   "metadata": {},
   "source": [
    "## 3. 详细模型评估\n",
    "\n",
    "对模型进行深入评估：\n",
    "1. 混淆矩阵分析\n",
    "2. ROC曲线和AUC\n",
    "3. 精确率-召回率曲线\n",
    "4. 不同阈值下的性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型预测概率\n",
    "def get_predictions_proba(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            outputs = model(features)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy()[:, 1])\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "# 获取各个模型在测试集上的预测概率\n",
    "mlp_probs, _ = get_predictions_proba(mlp_model, test_loader, device)\n",
    "svm_probs = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "rf_probs = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 1. 混淆矩阵分析\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.show()\n",
    "\n",
    "# 绘制每个模型的混淆矩阵\n",
    "plot_confusion_matrix(y_test, (mlp_probs > 0.5).astype(int), 'MLP模型混淆矩阵')\n",
    "plot_confusion_matrix(y_test, (svm_probs > 0.5).astype(int), 'SVM模型混淆矩阵')\n",
    "plot_confusion_matrix(y_test, (rf_probs > 0.5).astype(int), '随机森林模型混淆矩阵')\n",
    "\n",
    "# 2. ROC曲线分析\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 计算并绘制每个模型的ROC曲线\n",
    "for probs, name in [(mlp_probs, 'MLP'), (svm_probs, 'SVM'), (rf_probs, 'Random Forest')]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('假阳性率')\n",
    "plt.ylabel('真阳性率')\n",
    "plt.title('ROC曲线比较')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3. 精确率-召回率曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for probs, name in [(mlp_probs, 'MLP'), (svm_probs, 'SVM'), (rf_probs, 'Random Forest')]:\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "    avg_precision = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'{name} (AP = {avg_precision:.3f})')\n",
    "\n",
    "plt.xlabel('召回率')\n",
    "plt.ylabel('精确率')\n",
    "plt.title('精确率-召回率曲线比较')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4. 不同阈值下的性能分析\n",
    "def threshold_performance(y_true, y_prob, thresholds):\n",
    "    metrics = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "        metrics.append({\n",
    "            'threshold': threshold,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# 分析不同阈值\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "mlp_threshold_metrics = threshold_performance(y_test, mlp_probs, thresholds)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(mlp_threshold_metrics['threshold'], mlp_threshold_metrics['precision'], label='精确率')\n",
    "plt.plot(mlp_threshold_metrics['threshold'], mlp_threshold_metrics['recall'], label='召回率')\n",
    "plt.plot(mlp_threshold_metrics['threshold'], mlp_threshold_metrics['f1'], label='F1分数')\n",
    "plt.xlabel('阈值')\n",
    "plt.ylabel('分数')\n",
    "plt.title('MLP模型在不同阈值下的性能')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 打印最佳阈值\n",
    "best_threshold_idx = mlp_threshold_metrics['f1'].idxmax()\n",
    "best_threshold = mlp_threshold_metrics.loc[best_threshold_idx]\n",
    "print(f\"MLP模型的最佳阈值: {best_threshold['threshold']:.2f}\")\n",
    "print(f\"在最佳阈值下的性能:\")\n",
    "print(f\"精确率: {best_threshold['precision']:.4f}\")\n",
    "print(f\"召回率: {best_threshold['recall']:.4f}\")\n",
    "print(f\"F1分数: {best_threshold['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0100db",
   "metadata": {},
   "source": [
    "## 4. 错误分析与模型解释\n",
    "\n",
    "分析模型的预测错误：\n",
    "1. 错误预测案例分析\n",
    "2. 特征重要性分析\n",
    "3. 模型预测置信度分析\n",
    "4. 改进建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 错误预测案例分析\n",
    "def analyze_errors(y_true, y_pred, probs, features, n_samples=5):\n",
    "    errors = y_true != y_pred\n",
    "    error_indices = np.where(errors)[0]\n",
    "    \n",
    "    print(f\"错误预测总数: {len(error_indices)}\")\n",
    "    print(f\"错误率: {len(error_indices) / len(y_true):.2%}\")\n",
    "    \n",
    "    # 随机选择一些错误案例\n",
    "    if len(error_indices) > n_samples:\n",
    "        sample_indices = np.random.choice(error_indices, n_samples, replace=False)\n",
    "    else:\n",
    "        sample_indices = error_indices\n",
    "    \n",
    "    print(\"\\n错误预测案例分析:\")\n",
    "    for idx in sample_indices:\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"案例 {idx}:\")\n",
    "        print(f\"真实标签: {y_true[idx]}\")\n",
    "        print(f\"预测标签: {y_pred[idx]}\")\n",
    "        print(f\"预测概率: {probs[idx]:.4f}\")\n",
    "        print(f\"特征值前10个: {features[idx][:10]}\")\n",
    "\n",
    "# 分析MLP模型的错误预测\n",
    "mlp_pred = (mlp_probs > best_threshold['threshold']).astype(int)\n",
    "analyze_errors(y_test, mlp_pred, mlp_probs, X_test_scaled)\n",
    "\n",
    "# 2. 特征重要性分析（使用随机森林模型）\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': range(X_train.shape[1]),\n",
    "    'importance': rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(20), feature_importance['importance'][:20])\n",
    "plt.title('Top 20 最重要特征')\n",
    "plt.xlabel('特征索引')\n",
    "plt.ylabel('重要性')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. 预测置信度分析\n",
    "def analyze_confidence(probs, y_true):\n",
    "    correct = (probs > 0.5).astype(int) == y_true\n",
    "    confidence_bins = np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    \n",
    "    for i in range(len(confidence_bins)-1):\n",
    "        mask = (probs >= confidence_bins[i]) & (probs < confidence_bins[i+1])\n",
    "        if mask.any():\n",
    "            n_samples = mask.sum()\n",
    "            accuracy = correct[mask].mean()\n",
    "            print(f\"置信度 {confidence_bins[i]:.1f}-{confidence_bins[i+1]:.1f}: \"\n",
    "                  f\"样本数={n_samples}, 准确率={accuracy:.2%}\")\n",
    "\n",
    "print(\"\\nMLP模型预测置信度分析:\")\n",
    "analyze_confidence(mlp_probs, y_test)\n",
    "\n",
    "print(\"\\nSVM模型预测置信度分析:\")\n",
    "analyze_confidence(svm_probs, y_test)\n",
    "\n",
    "print(\"\\n随机森林模型预测置信度分析:\")\n",
    "analyze_confidence(rf_probs, y_test)\n",
    "\n",
    "# 4. 模型集成分析\n",
    "# 使用投票方式集成三个模型的预测\n",
    "ensemble_pred = ((mlp_probs > 0.5).astype(int) +\n",
    "                (svm_probs > 0.5).astype(int) +\n",
    "                (rf_probs > 0.5).astype(int)) >= 2\n",
    "\n",
    "ensemble_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, ensemble_pred),\n",
    "    **dict(zip(\n",
    "        ['precision', 'recall', 'f1', '_'],\n",
    "        precision_recall_fscore_support(y_test, ensemble_pred, average='binary')\n",
    "    ))\n",
    "}\n",
    "\n",
    "print(\"\\n集成模型性能：\")\n",
    "print(ensemble_metrics)\n",
    "\n",
    "# 将集成模型添加到比较中\n",
    "models_comparison.loc['Ensemble'] = ensemble_metrics\n",
    "\n",
    "# 更新模型比较图\n",
    "plt.figure(figsize=(12, 6))\n",
    "models_comparison[['accuracy', 'precision', 'recall', 'f1']].plot(kind='bar')\n",
    "plt.title('所有模型性能比较（包含集成模型）')\n",
    "plt.xlabel('模型')\n",
    "plt.ylabel('分数')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3643356",
   "metadata": {},
   "source": [
    "## 5. 总结与改进建议\n",
    "\n",
    "基于上述分析，我们得出以下结论：\n",
    "\n",
    "1. **模型性能比较**\n",
    "   - 各个模型的优缺点\n",
    "   - 最佳模型的选择\n",
    "   - 集成方法的效果\n",
    "\n",
    "2. **关键发现**\n",
    "   - 最重要的特征\n",
    "   - 常见的错误类型\n",
    "   - 模型的置信度特征\n",
    "\n",
    "3. **改进建议**\n",
    "   - 特征工程优化\n",
    "   - 模型架构改进\n",
    "   - 集成策略优化\n",
    "   - 数据增强方案\n",
    "\n",
    "4. **部署建议**\n",
    "   - 模型选择\n",
    "   - 阈值设置\n",
    "   - 监控指标"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
