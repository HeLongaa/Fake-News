import streamlit as st
import torch
from PIL import Image
import os
from models import Mynet
from config import Config
import torch.nn.functional as F
from transformers import BertTokenizer
import torchvision.transforms as transforms
import glob

class FakeNewsDetector:
    def __init__(self):
        self.config = Config()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.available_models = self.get_available_models()
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                              std=[0.229, 0.224, 0.225])
        ])
        
    def get_available_models(self):
        """èŽ·å–æ‰€æœ‰å·²ä¿å­˜çš„æ¨¡åž‹æ–‡ä»¶"""
        model_files = glob.glob('model/*.ckpt')
        models = {}
        
        for model_file in model_files:
            filename = os.path.basename(model_file)
            # è§£æžæ–‡ä»¶åä»¥èŽ·å–BERTå’ŒResNetç±»åž‹
            if filename.startswith('S_'):  # å¯¹æ¯”å­¦ä¹ æ¨¡åž‹
                parts = filename[2:-5].split('_')  # ç§»é™¤'S_'å‰ç¼€å’Œ'.ckpt'åŽç¼€
                bert_type = parts[0]
                resnet_type = parts[1]
                
                # åˆ›å»ºç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºåç§°
                display_name = self.get_model_display_name(bert_type, resnet_type)
                models[display_name] = {
                    'path': model_file,
                    'bert_type': bert_type,
                    'resnet_type': resnet_type,
                    'use_sloss': True
                }
            else:
                parts = filename[:-5].split('_')  # ç§»é™¤'.ckpt'åŽç¼€
                bert_type = parts[0]
                resnet_type = parts[1]
                
                display_name = self.get_model_display_name(bert_type, resnet_type)
                models[display_name] = {
                    'path': model_file,
                    'bert_type': bert_type,
                    'resnet_type': resnet_type,
                    'use_sloss': False
                }
        
        return models
    
    def get_model_display_name(self, bert_type, resnet_type):
        """ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æ¨¡åž‹æ˜¾ç¤ºåç§°"""
        bert_names = {
            'bert-base-chinese': 'BERT-baseä¸­æ–‡',
            'chinese-bert-wwm-ext': 'BERT-wwm-extä¸­æ–‡',
            'minirbt-h256': 'MiniRBT-H256'
        }
        
        bert_display = bert_names.get(bert_type, bert_type)
        return f"{bert_display} + {resnet_type.upper()}"

    def load_model(self, model_info):
        """åŠ è½½é€‰å®šçš„æ¨¡åž‹"""
        self.config.bert_name = f'bert_model/{model_info["bert_type"]}'
        self.config.resnet_name = model_info['resnet_type']
        self.config.usesloss = model_info['use_sloss']
        
        # æ›´æ–°æ¨¡åž‹é…ç½®
        if model_info['bert_type'] == 'minirbt-h256':
            self.config.bert_fc = 256
        else:
            self.config.bert_fc = 768
        self.config.resnet_fc = self.config.bert_fc
        
        # åŠ è½½æ¨¡åž‹
        model = Mynet(self.config).to(self.device)
        model.load_state_dict(torch.load(model_info['path'], map_location=self.device))
        model.eval()
        return model, BertTokenizer.from_pretrained(f'bert_model/{model_info["bert_type"]}')

    def predict(self, text, image, model, tokenizer):
        """è¿›è¡Œé¢„æµ‹"""
        # å¤„ç†æ–‡æœ¬
        encoded = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.config.pad_size,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
    
        # å¤„ç†å›¾åƒ
        if image is not None:
            image = self.transform(image).unsqueeze(0).to(self.device)
        else:
            # å¦‚æžœæ²¡æœ‰å›¾åƒï¼Œåˆ›å»ºä¸€ä¸ªå…¨é›¶çš„å›¾åƒå¼ é‡
            image = torch.zeros((1, 3, 224, 224)).to(self.device)
        
        # èŽ·å–é¢„æµ‹ç»“æžœ
        with torch.no_grad():
            text_input = encoded['input_ids'].to(self.device)
            attention_mask = encoded['attention_mask'].to(self.device)
            
            # å°†è¾“å…¥ç»„åˆæˆå…ƒç»„ä¼ é€’ç»™æ¨¡åž‹
            inputs = (image, text_input, attention_mask)
            outputs = model(inputs)
            
            probabilities = outputs if isinstance(outputs, torch.Tensor) else outputs[0]
            if not isinstance(probabilities, torch.Tensor):
                probabilities = torch.tensor(probabilities)
            
            # å¦‚æžœè¾“å‡ºæ²¡æœ‰ç»è¿‡softmaxï¼Œåˆ™åº”ç”¨softmax
            if probabilities.dim() == 2:  # logits
                probabilities = F.softmax(probabilities, dim=1)
                
        return probabilities.cpu().numpy()[0]

def main():
    st.set_page_config(
        page_title="å¤šæ¨¡æ€å‡æ–°é—»æ£€æµ‹ç³»ç»Ÿ",
        page_icon="ðŸ”",
        layout="wide"
    )
    
    st.title("å¤šæ¨¡æ€å‡æ–°é—»æ£€æµ‹ç³»ç»Ÿ")
    
    detector = FakeNewsDetector()
    
    if not detector.available_models:
        st.error("æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡åž‹æ–‡ä»¶ï¼è¯·ç¡®ä¿æ¨¡åž‹æ–‡ä»¶å­˜æ”¾åœ¨æ­£ç¡®çš„ä½ç½®ã€‚")
        return
    
    # æ¨¡åž‹é€‰æ‹©
    st.sidebar.header("æ¨¡åž‹é…ç½®")
    model_name = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡åž‹",
        list(detector.available_models.keys())
    )
    
    # æ˜¾ç¤ºæ¨¡åž‹ä¿¡æ¯
    model_info = detector.available_models[model_name]
    st.sidebar.write("æ¨¡åž‹ä¿¡æ¯ï¼š")
    st.sidebar.write(f"- BERTç±»åž‹ï¼š{model_info['bert_type']}")
    st.sidebar.write(f"- ResNetç±»åž‹ï¼š{model_info['resnet_type']}")
    st.sidebar.write(f"- ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ï¼š{'æ˜¯' if model_info['use_sloss'] else 'å¦'}")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("æ–‡æœ¬è¾“å…¥")
        news_text = st.text_area("è¯·è¾“å…¥æ–°é—»æ–‡æœ¬", height=200)
        
    with col2:
        st.subheader("å›¾ç‰‡ä¸Šä¼ ")
        uploaded_file = st.file_uploader("ä¸Šä¼ æ–°é—»å›¾ç‰‡", type=['jpg', 'jpeg', 'png'])
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)
        
    # æ£€æµ‹æŒ‰é’®
    if st.button("å¼€å§‹æ£€æµ‹", type="primary"):
        if not news_text:
            st.error("è¯·è¾“å…¥æ–°é—»æ–‡æœ¬ï¼")
            return
            
        try:
            # åŠ è½½é€‰å®šçš„æ¨¡åž‹
            model, tokenizer = detector.load_model(model_info)
            
            # å¤„ç†å›¾ç‰‡
            image_data = Image.open(uploaded_file) if uploaded_file else None
            
            with st.spinner('æ­£åœ¨è¿›è¡Œæ£€æµ‹...'):
                # è¿›è¡Œé¢„æµ‹
                probabilities = detector.predict(news_text, image_data, model, tokenizer)
            
            # æ˜¾ç¤ºç»“æžœ
            st.subheader("æ£€æµ‹ç»“æžœ")
            
            # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºæ¦‚çŽ‡
            col1, col2 = st.columns(2)
            with col1:
                st.write("çœŸå®žæ–°é—»æ¦‚çŽ‡")
                st.progress(float(probabilities[0]))
                st.write(f"{probabilities[0]*100:.2f}%")
                
            with col2:
                st.write("è™šå‡æ–°é—»æ¦‚çŽ‡")
                st.progress(float(probabilities[1]))
                st.write(f"{probabilities[1]*100:.2f}%")
            
            # ç»“è®º
            if probabilities[1] > probabilities[0]:
                st.error("âš ï¸ ç³»ç»Ÿåˆ¤å®šï¼šè¯¥æ–°é—»å¯èƒ½æ˜¯è™šå‡æ–°é—»ï¼")
                if probabilities[1] > 0.8:
                    st.write("ç½®ä¿¡åº¦ï¼šé«˜")
                else:
                    st.write("ç½®ä¿¡åº¦ï¼šä¸­ç­‰")
            else:
                st.success("âœ… ç³»ç»Ÿåˆ¤å®šï¼šè¯¥æ–°é—»å¯èƒ½æ˜¯çœŸå®žæ–°é—»ã€‚")
                if probabilities[0] > 0.8:
                    st.write("ç½®ä¿¡åº¦ï¼šé«˜")
                else:
                    st.write("ç½®ä¿¡åº¦ï¼šä¸­ç­‰")
                
        except Exception as e:
            st.error(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯ï¼š{str(e)}")

if __name__ == "__main__":
    main()